{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  #Importing the module for regular expressions\n",
    "germ = open(\"Germplasm.tsv\", \"r\") #Opening the Germplasm file in read mode and assigning it to an object\n",
    "germ.seek(0)  #Taking the cursor to the beginning of the file\n",
    "germlist = []\n",
    "for line in germ.readlines()[1:]:    #iterate over each line in the file which are string, except over the first line, index 0, that are the headers\n",
    "    matchobj = re.search( r'^(AT[0-9]G[0-9]+)', line)#do a regular expression search for the locus codes and save the results in matchobj\n",
    "    germlist.append(matchobj.group(1)) #I create a list with all the locus codes to be able to compare it with the list from locusgene\n",
    "print(\"The AGI locus codes for Germplasm are\", \", \".join(germlist)) #print the results of the search for each line using the join function over the list with the codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "loc = open(\"LocusGene.tsv\", \"r\")\n",
    "loclist = []\n",
    "for line in loc.readlines()[1:]:\n",
    "    matchobj = re.search( r'^(AT[0-9]G[0-9]+)', line)\n",
    "    loclist.append(matchobj.group(1))\n",
    "print(\"The AGI locus codes for LocusGene are\", \", \".join(loclist))\n",
    "loc.seek(0)   # set it back to the beginning again for this lesson..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if germlist == loclist:\n",
    "    print(\"Both documents follow the same locus sequence\")\n",
    "else:\n",
    "    print(\"The documents do not follow the same sequence\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I performed a regular expression search over the databases to check if both locus codes where written equally and then append them to a list to be able to check if they followed they same order. \n",
    "In the last box of code we can see how the two lists created are equal, therefore the lists follow the same order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Design and create the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "#%config SqlMagic.autocommit=False\n",
    "%sql mysql+pymysql://root:root@127.0.0.1:3306/mysql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%sql drop database exam_week_2\n",
    "%sql create database exam_week_2;\n",
    "%sql show databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql use exam_week_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous lines of code I have loaded de sqlmagic extension and created the database that I will be using for this exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                                user='root',\n",
    "                                password='root',\n",
    "                                db='exam_week_2',  #the database is exam_week_2 as shown above\n",
    "                                charset='utf8mb4', \n",
    "                                cursorclass=pymysql.cursors.DictCursor)\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        with open('Germplasm.tsv') as csvfile:    \n",
    "            cursor.execute(\"drop table germplasm\")  #this line is just in case the base was created previously\n",
    "            germ = open(\"Germplasm.tsv\", \"r\") #open the tsv in read mode and save it in germ\n",
    "            germplasm = germ.readlines()      #reading the lines in the tsv via the germ object and saving them into the object germplasm\n",
    "            import re\n",
    "            mo = re.search( r'([^\\t]+)\\t([^\\t]+)\\t([^\\t]+)\\t([^\\t]+)[\\n]', germplasm[0]) #performing a regular expression search to obtain the columns of the header, the text we are reading is the first row of the document\n",
    "            colnames = [mo.group(1), mo.group(2), mo.group(3), mo.group(4)]   #saving the names of the columns in a list using the differents group of group method for mo\n",
    "            sql = \"CREATE TABLE germplasm( \" +colnames[0] + \" VARCHAR(12) NOT NULL PRIMARY KEY, \" +colnames[1] + \" VARCHAR(30) NOT NULL, \" + colnames[2] + \" VARCHAR(600) NOT NULL, \" + colnames[3] + \" INTEGER NOT NULL)\" #creating the sql tables with the header names from the colnames list\n",
    "            cursor.execute(sql)\n",
    "            connection.commit() # NOTE THAT I AM FORCING THE WRITE TO THE DATABASE HERE\n",
    "\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close() # if I close before I commit, the inserts are lostprint(colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from germplasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                                user='root',\n",
    "                                password='root',\n",
    "                                db='exam_week_2',\n",
    "                                charset='utf8mb4', # note utf8... this is important for unusual characters!\n",
    "                                cursorclass=pymysql.cursors.DictCursor)\n",
    "#onnection.autocommit = False\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        with open('LocusGene.tsv') as csvfile:\n",
    "            cursor.execute(\"drop table locus\")\n",
    "            loc = open(\"LocusGene.tsv\", \"r\")\n",
    "            locus = loc.readlines()\n",
    "            import re\n",
    "            mo = re.search( r'([^\\t]+)\\t([^\\t]+)\\t([^\\t]+)[\\n]', locus[0])\n",
    "            colnames1 = [mo.group(1), mo.group(2), mo.group(3)]\n",
    "            sql = \"CREATE TABLE locus( \" +colnames1[0] + \" VARCHAR(20) NOT NULL PRIMARY KEY, \" +colnames1[1] + \" VARCHAR(30) NOT NULL, \" + colnames1[2] + \" INTEGER NOT NULL)\"\n",
    "            cursor.execute(sql)\n",
    "            connection.commit() # NOTE THAT I AM FORCING THE WRITE TO THE DATABASE HERE\n",
    "\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close() # if I close before I commit, the inserts are lostprint(colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from locus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lines above I have created the two tables using the headers from their respective tsv files using pymysql and regular expression searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Fill the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql.cursors\n",
    "import csv\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='exam_week_2',\n",
    "                             charset='utf8mb4',  # note utf8... this is important for unusual characters!\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "connection.autocommit = False\n",
    "\n",
    "    \n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        with open('Germplasm.tsv') as csvfile:   \n",
    "            res = csv.DictReader(csvfile, delimiter=\"\\t\", quotechar='\"') #I am saving the lines from Dictreader as rows in which the values are quoted and separated by tab\n",
    "            for row in res:   #I am iterating over the object created before which is a dictreader that maps the operation of each row into a dict\n",
    "                sql = \"\"\"INSERT INTO germplasm (Locus, germplasm, phenotype, pubmed) values       \n",
    "                ('{}', '{}','{}',{})\"\"\".format(row[colnames[0]], row[colnames[1]], row[colnames[2]],row[colnames[3]]) #I am iterating over the res object, obtaining rows which are dictionaries. Then extracting the values that are paired with the colnames keys\n",
    "                cursor.execute(sql)\n",
    "            connection.commit() \n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%sql select * from germplasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql.cursors\n",
    "import csv\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='exam_week_2',\n",
    "                             charset='utf8mb4',  \n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "connection.autocommit = False\n",
    "\n",
    "    \n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        with open('LocusGene.tsv') as csvfile:\n",
    "            res = csv.DictReader(csvfile, delimiter=\"\\t\", quotechar='\"')\n",
    "            for row in res:\n",
    "                sql = \"\"\"INSERT INTO locus (Locus, Gene, ProteinLength) values       \n",
    "                ('{}', '{}',{})\"\"\".format(row[colnames1[0]], row[colnames1[1]], row[colnames1[2]]) \n",
    "                cursor.execute(sql)\n",
    "            connection.commit()\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from locus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have filled the tables using pymsql and basic for loops and iterable commands and indexation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Create reports, written to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a report that shows the full, joined, content of the two database tables (including a header line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM germplasm INNER JOIN locus ON germplasm.Locus = locus.Locus;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am checking if the sql syntax is correct before trying to work with pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pymysql.cursors\n",
    "import csv\n",
    "import io\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='exam_week_2',\n",
    "                             charset='utf8mb4',  # note utf8... this is important for unusual characters!\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "connection.autocommit = False\n",
    "\n",
    "    \n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        sql = \"\"\"SELECT * FROM germplasm INNER JOIN locus ON germplasm.Locus = locus.Locus;\"\"\" #I am creating the joined table\n",
    "        cursor.execute(sql) \n",
    "        results = cursor.fetchall()            #saving the table in the object results which is a list of dictionaries\n",
    "        report = \"\\t\".join(list(results[0].keys())) #creating the header for the document joining the keys of the first dict in the list, although I could have used any dict. And saving it in the object report\n",
    "        for dicc in results:      #iterating over the list, taking the dictionaries in the object dicc\n",
    "            linea = []            #creating a new list\n",
    "            for value in dicc.values():   #iterating over the values in each dictionary\n",
    "                linea.append(str(value))  #appending the values in the list, after changing their type to strings, necessary for the columns formed by integers because if not done you can not concatenate the values.\n",
    "            report = report + \"\\n\" + \"\\t\".join(linea)   #adding a newline to reports to separete the previous row or line from the actual one. Then joined the values of the dicts with a tab as the separator.\n",
    "        docc = open(\"Report.tsv\", \"w\")     #opening the file in which I will pour the tables in write mode\n",
    "        docc.write(report)                 #writing in the file the report object comprised by the header and the values\n",
    "        docc.close()\n",
    "        \n",
    "        connection.commit()\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used the INNER JOIN because both tables were joined in a 1:1 manner and there was no missing or null information in any of them. The way I have written the next data into the tsv file is simmilar to the one explained here therefore I won't go into as much detail in the next exercises regarding this aspect of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a joined report that only includes the Genes SKOR and MAA3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsv_append(results):\n",
    "    \"\"\"function that appends the headers and values from a list of dictionaries into a object that will be written later into the tsv file\"\"\"\n",
    "    report = \"\\n\" + \"\\t\".join(list(results[0].keys())) #I am writting this file into the tsv file the same way I did in the previous exercises.\n",
    "    for dicc in results:\n",
    "        linea = []\n",
    "        for value in dicc.values():\n",
    "            linea.append(str(value))\n",
    "        report = report + \"\\n\" + \"\\t\".join(linea)\n",
    "    return report\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am creating a function to ease the task of changing the list of dictionaries into a string to be able to write it in the tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Locus': 'AT3G02850', 'germplasm': 'CS3816', 'phenotype': 'The skor-1 mutant is sensitive to toxic cations in addition to K+ depletion.', 'pubmed': 17568770, 'locus.Locus': 'AT3G02850', 'Gene': 'SKOR', 'ProteinLength': 234}, {'Locus': 'AT4G15570', 'germplasm': 'maa3', 'phenotype': 'Homozygotes are not recovered. Female gametophyte development is delayed and asynchronous. During fertilization, fusion of polar nuclei does not occur. Polar nuclei nucloeli are smaller than WT.', 'pubmed': 18772186, 'locus.Locus': 'AT4G15570', 'Gene': 'MAA3', 'ProteinLength': 294}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='exam_week_2',\n",
    "                             charset='utf8mb4',  # note utf8... this is important for unusual characters!\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "connection.autocommit = False\n",
    "\n",
    "    \n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        sql = \"\"\"SELECT * FROM germplasm INNER JOIN locus ON germplasm.Locus = locus.Locus WHERE locus.Gene IN (\"SKOR\", \"MAA3\");\"\"\" #I am creating the joined table using sql syntax\n",
    "        cursor.execute(sql) \n",
    "        results = cursor.fetchall()\n",
    "        report = tsv_append(results)\n",
    "        docc = open(\"Report.tsv\", \"a\")            #The opening mode of the document has been changed from write to append in order not to overwrite the file\n",
    "        docc.write(report)\n",
    "        docc.close()\n",
    "        \n",
    "        connection.commit() \n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a report that counts the number of entries for each Chromosome (AT1Gxxxxxx to AT5Gxxxxxxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='exam_week_2',\n",
    "                             charset='utf8mb4',  # note utf8... this is important for unusual characters!\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "connection.autocommit = False\n",
    "\n",
    "    \n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        sql = \"\"\"SELECT * FROM germplasm INNER JOIN locus ON germplasm.Locus = locus.Locus;\"\"\" #I am creating the joined table\n",
    "        cursor.execute(sql) \n",
    "        results = cursor.fetchall()\n",
    "        codes = []                  #creating a list called codes\n",
    "        for dicc in results:        #iterating over the dictionaries in the dictionaries list results\n",
    "            codes.append(dicc[\"Locus\"])   #appending the values of the key Locus for all the dicts in the codes list \n",
    "        searchobj = \"\\t\".join(codes)      #joining the values of Locus code AIG with a tab value and saving it into the searcobj object which is a string\n",
    "        mo1 = re.findall( r'AT1G[0-9]+\\t', searchobj)    #doing a regular expresion search for the locus codes from each chromosome and saving it into a mo object. findall returns all the values that match the reg expr.\n",
    "        mo2 = re.findall( r'AT2G[0-9]+\\t', searchobj)\n",
    "        mo3 = re.findall( r'AT3G[0-9]+\\t', searchobj)\n",
    "        mo4 = re.findall( r'AT4G[0-9]+\\t', searchobj)\n",
    "        mo5 = re.findall( r'AT5G[0-9]+\\t?', searchobj)\n",
    "    \n",
    "    lista1 = [{\"Chromosome\" : \"1\", \"Chrom_entries\": len(mo1)}, {\"Chromosome\" : \"2\", \"Chrom_entries\": len(mo2)}, {\"Chromosome\" : \"3\", \"Chrom_entries\": len(mo3)}, {\"Chromosome\" : \"4\", \"Chrom_entries\": len(mo4)}, {\"Chromosome\" : \"5\", \"Chrom_entries\": len(mo5)}] #creating a list of dictionaries with the chromosome number and the number of entries that come from that chromosome.\n",
    "    report = tsv_append(lista1)\n",
    "    docc = open(\"Report.tsv\", \"a\")\n",
    "    docc.write(report)\n",
    "    docc.close()\n",
    "        \n",
    "    connection.commit()\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a report that shows the average protein length for the genes on each Chromosome (AT1Gxxxxxx to AT5Gxxxxxxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                                user='root',\n",
    "                                password='root',\n",
    "                                db='exam_week_2',\n",
    "                                charset='utf8mb4', # note utf8... this is important for unusual characters!\n",
    "                                cursorclass=pymysql.cursors.DictCursor)\n",
    "#onnection.autocommit = False\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        with open('LocusGene.tsv') as csvfile:\n",
    "            sql = \"drop table chromosome\" #dropping the table just in case it was created earlier\n",
    "            cursor.execute(sql)\n",
    "            loc = open(\"LocusGene.tsv\", \"r\")   #I open the document in read mode and saved it in the loc object\n",
    "            locus = loc.readlines()            #this creates and object that is a list with a line en every index, the values separated by \\t and there is a \\n at the end of each line\n",
    "            import re\n",
    "            mo = re.search( r'([^\\t]+)\\t([^\\t]+)\\t([^\\t]+)[\\n]', locus[0])       #search object to obtain the header values, they are in the index 0 of the list\n",
    "            colnames1 = [mo.group(1), mo.group(2), mo.group(3)]                  #creating a list filled with the header values\n",
    "            sql = \"CREATE TABLE chromosome( \" +colnames1[0] + \" VARCHAR(20) NOT NULL PRIMARY KEY, \" +colnames1[1] + \" VARCHAR(30) NOT NULL, \" + colnames1[2] + \" INTEGER NOT NULL, chromnumber VARCHAR(2) NOT NULL  )\" #using the previous list I write the name for each column\n",
    "            cursor.execute(sql)\n",
    "            connection.commit() # NOTE THAT I AM FORCING THE WRITE TO THE DATABASE HERE\n",
    "\n",
    "finally:\n",
    "    print(\"\")\n",
    "    #connection.close() # if I close before I commit, the inserts are lostprint(colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql show databases\n",
    "%sql use exam_week_2\n",
    "%sql show tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql.cursors\n",
    "import csv\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='exam_week_2',\n",
    "                             charset='utf8mb4',  # note utf8... this is important for unusual characters!\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "connection.autocommit = False\n",
    "\n",
    "    \n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        with open('LocusGene.tsv') as csvfile:       #I have filled this new table that contains a new column in a simmilar manner to the described in problem 3\n",
    "            res = csv.DictReader(csvfile, delimiter=\"\\t\", quotechar='\"')   \n",
    "            for row in res:\n",
    "                sql = \"INSERT INTO chromosome (Locus, Gene, ProteinLength, chromnumber ) values   ('{}', '{}',{}, '{}')\".format(row[colnames1[0]], row[colnames1[1]], row[colnames1[2]], row[colnames1[0]][2])\n",
    "                cursor.execute(sql)\n",
    "            connection.commit() \n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT chromnumber, AVG(ProteinLength) FROM chromosome GROUP BY chromnumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pymysql.cursors\n",
    "import csv\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='exam_week_2',\n",
    "                             charset='utf8mb4',  # note utf8... this is important for unusual characters!\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "connection.autocommit = False\n",
    "        \n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        sql = \"\"\"SELECT chromnumber, AVG(ProteinLength) FROM chromosome GROUP BY chromnumber;\"\"\" #thanks to sql syntax I can pair the chromosomes number to the average protein length of the entries for that chromosome\n",
    "        cursor.execute(sql)\n",
    "        results = cursor.fetchall()\n",
    "        report = tsv_append(results)\n",
    "        docc = open(\"Report.tsv\", \"a\")\n",
    "        docc.write(report)\n",
    "        docc.close()\n",
    "        connection.commit()\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
