{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student name: Jesús González Ferrer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  #Importing the module for regular expressions\n",
    "germ = open(\"Germplasm.tsv\", \"r\") #Opening the Germplasm file in read mode and assigning it to an object\n",
    "germ.seek(0)  #Taking the cursor to the beginning of the file\n",
    "germlist = [] #creating a list\n",
    "for line in germ.readlines()[1:]:    #iterate over each line in the file that are treates as strings, except over the first line, index 0, that is the headers\n",
    "    matchobj = re.search( r'^(AT[0-9]G[0-9]+)', line) #do a regular expression search for the locus codes and save the results in matchobj\n",
    "    germlist.append(matchobj.group(1)) #I create a list with all the locus codes to be able to compare it with the list from locusgene\n",
    "print(\"The AGI locus codes for Germplasm are\", \", \".join(germlist)) #print the results of the search for each line using the join function over the list with the codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "loc = open(\"LocusGene.tsv\", \"r\")\n",
    "loclist = []\n",
    "for line in loc.readlines()[1:]:\n",
    "    matchobj = re.search( r'^(AT[0-9]G[0-9]+)', line)\n",
    "    loclist.append(matchobj.group(1))\n",
    "print(\"The AGI locus codes for LocusGene are\", \", \".join(loclist))\n",
    "loc.seek(0)   # set it back to the beginning again for this lesson..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if germlist == loclist:\n",
    "    print(\"Both documents follow the same locus sequence\")\n",
    "else:\n",
    "    print(\"The documents do not follow the same sequence\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I performed a regular expression search over the databases to check if both locus codes where written equally and then append them to a list to be able to check if they followed they same order. \n",
    "In the last box of code we can see how the two lists created are equal, therefore the lists follow the same order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Design and create the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "#%config SqlMagic.autocommit=False\n",
    "%sql mysql+pymysql://root:root@127.0.0.1:3306/mysql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%sql drop database exam_week_2\n",
    "%sql create database exam_week_2;\n",
    "%sql show databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql show databases\n",
    "%sql use exam_week_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous lines of code I have loaded de sqlmagic extension and created the database that I will be using for this exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                                user='root',\n",
    "                                password='root',\n",
    "                                db='exam_week_2',  #the database is exam_week_2 as shown above\n",
    "                                charset='utf8mb4', \n",
    "                                cursorclass=pymysql.cursors.DictCursor)\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        with open('Germplasm.tsv') as csvfile:    \n",
    "            germ = open(\"Germplasm.tsv\", \"r\") #open the tsv in read mode and save it in germ\n",
    "            germplasm = germ.readlines()      #reading the lines in the tsv via the germ object and saving them into the object germplasm\n",
    "            import re\n",
    "            mo = re.search( r'([^\\t]+)\\t([^\\t]+)\\t([^\\t]+)\\t([^\\t]+)[\\n]', germplasm[0]) #performing a regular expression search to obtain the columns of the header, the text we are reading is the first row of the document\n",
    "            colnames = [mo.group(1), mo.group(2), mo.group(3), mo.group(4)]   #saving the names of the columns in a list using the differents group of group method for mo\n",
    "            sql = \"CREATE TABLE germplasm( \" +colnames[0] + \" VARCHAR(12) NOT NULL PRIMARY KEY, \" +colnames[1] + \" VARCHAR(30) NOT NULL, \" + colnames[2] + \" VARCHAR(600) NOT NULL, \" + colnames[3] + \" INTEGER NOT NULL)\" #creating the sql tables with the header names from the colnames list\n",
    "            cursor.execute(sql)\n",
    "            connection.commit() # NOTE THAT I AM FORCING THE WRITE TO THE DATABASE HERE\n",
    "\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close() # if I close before I commit, the inserts are lostprint(colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from germplasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                                user='root',\n",
    "                                password='root',\n",
    "                                db='exam_week_2',\n",
    "                                charset='utf8mb4', # note utf8... this is important for unusual characters!\n",
    "                                cursorclass=pymysql.cursors.DictCursor)\n",
    "#onnection.autocommit = False\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        with open('LocusGene.tsv') as csvfile:\n",
    "            loc = open(\"LocusGene.tsv\", \"r\")\n",
    "            locus = loc.readlines()\n",
    "            import re\n",
    "            mo = re.search( r'([^\\t]+)\\t([^\\t]+)\\t([^\\t]+)[\\n]', locus[0])\n",
    "            colnames1 = [mo.group(1), mo.group(2), mo.group(3)]\n",
    "            sql = \"CREATE TABLE locus( \" +colnames1[0] + \" VARCHAR(20) NOT NULL PRIMARY KEY, \" +colnames1[1] + \" VARCHAR(30) NOT NULL, \" + colnames1[2] + \" INTEGER NOT NULL)\"\n",
    "            cursor.execute(sql)\n",
    "            connection.commit() # NOTE THAT I AM FORCING THE WRITE TO THE DATABASE HERE\n",
    "\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close() # if I close before I commit, the inserts are lostprint(colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from locus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lines above I have created the two tables using the headers from their respective tsv files using pymysql and regular expression searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Fill the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql.cursors\n",
    "import csv\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='exam_week_2',\n",
    "                             charset='utf8mb4',  # note utf8... this is important for unusual characters!\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "connection.autocommit = False\n",
    "\n",
    "    \n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        with open('Germplasm.tsv') as csvfile:   \n",
    "            res = csv.DictReader(csvfile, delimiter=\"\\t\", quotechar='\"') #I am saving the lines from Dictreader as rows in which the values are quoted and separated by tab\n",
    "            for row in res:   #I am iterating over the object created before which is a dictreader that maps the operation of each row into a dict\n",
    "                sql = \"\"\"INSERT INTO germplasm (Locus, germplasm, phenotype, pubmed) values       \n",
    "                ('{}', '{}','{}',{})\"\"\".format(row[colnames[0]], row[colnames[1]], row[colnames[2]],row[colnames[3]]) #I am iterating over the res object, obtaining rows which are dictionaries. Then extracting the values that are paired with the colnames keys\n",
    "                cursor.execute(sql)\n",
    "            connection.commit() \n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%sql select * from germplasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql.cursors\n",
    "import csv\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='exam_week_2',\n",
    "                             charset='utf8mb4',  \n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "connection.autocommit = False\n",
    "\n",
    "    \n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        with open('LocusGene.tsv') as csvfile:\n",
    "            res = csv.DictReader(csvfile, delimiter=\"\\t\", quotechar='\"')\n",
    "            for row in res:\n",
    "                sql = \"\"\"INSERT INTO locus (Locus, Gene, ProteinLength) values       \n",
    "                ('{}', '{}',{})\"\"\".format(row[colnames1[0]], row[colnames1[1]], row[colnames1[2]]) \n",
    "                cursor.execute(sql)\n",
    "            connection.commit()\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from locus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have filled the tables using pymsql and basic for loops, iterable commands and sql syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Create reports, written to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a report that shows the full, joined, content of the two database tables (including a header line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM germplasm INNER JOIN locus ON germplasm.Locus = locus.Locus;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am checking if the sql syntax is correct before trying to work with pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql.cursors\n",
    "import csv\n",
    "import io\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='exam_week_2',\n",
    "                             charset='utf8mb4',  # note utf8... this is important for unusual characters!\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "connection.autocommit = False\n",
    "\n",
    "    \n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        sql = \"\"\"SELECT * FROM germplasm INNER JOIN locus ON germplasm.Locus = locus.Locus;\"\"\" #I am creating the joined table\n",
    "        cursor.execute(sql) \n",
    "        results = cursor.fetchall()            #saving the table in the object results which is a list of dictionaries\n",
    "        report = \"\\t\".join(list(results[0].keys())) #creating the header for the document joining the keys of the first dict in the list, although I could have used any dict. And saving it in the object report\n",
    "        for dicc in results:      #iterating over the list, taking the dictionaries in the object dicc\n",
    "            linea = []            #creating a new list\n",
    "            for value in dicc.values():   #iterating over the values in each dictionary\n",
    "                linea.append(str(value))  #appending the values in the list, after changing their type to strings, necessary for the columns formed by integers because if not done you can not concatenate the values.\n",
    "            report = report + \"\\n\" + \"\\t\".join(linea)   #adding a newline to reports to separete the previous row or line from the actual one. Then joined the values of the dicts with a tab as the separator.\n",
    "        docc = open(\"JGFReport.txt\", \"w\")     #opening the file in which I will pour the tables in write mode\n",
    "        docc.write(\"Hi Mark this is the text file where I will be writting the report that shows the full, joined, content of the two database tables \\n\" +report)                 #writing in the file the report object comprised by the header and the values\n",
    "        docc.close()\n",
    "        \n",
    "        connection.commit()\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used the INNER JOIN because both tables were joined in a 1:1 manner and there was no missing or null information in any of them. The way I have written the next data into the tsv file is simmilar to the one explained here therefore I won't go into as much detail in the next exercises regarding this aspect of the code. I had it written as a tsv file but switched to txt because of what you said during the class of the exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a joined report that only includes the Genes SKOR and MAA3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsv_append(results):\n",
    "    \"\"\"function that appends the headers and values from a list of dictionaries into a object that will be written later into the text file as a string\"\"\"\n",
    "    report = \"\\n\" + \"\\t\".join(list(results[0].keys())) ##creating the header for the document joining the keys of the first dict in the list.\n",
    "    for dicc in results:    #iterating over the list, taking the dictionaries in the object dicc\n",
    "        linea = []          #creating a new list\n",
    "        for value in dicc.values():      #iterating over the values in each dictionary\n",
    "            linea.append(str(value))    #appending the values in the list, after changing their type to strings, necessary for the columns formed by integers\n",
    "        report = report + \"\\n\" + \"\\t\".join(linea)  #adding a newline to reports to separate the previous row or line from the actual one while joining its values with \\t.\n",
    "    return report            #returning the object report to the global scope of the box code\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am creating a function to ease the task of changing the list of dictionaries into a string to be able to write it in the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='exam_week_2',\n",
    "                             charset='utf8mb4',  # note utf8... this is important for unusual characters!\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "connection.autocommit = False\n",
    "\n",
    "    \n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        sql = \"\"\"SELECT * FROM germplasm INNER JOIN locus ON germplasm.Locus = locus.Locus WHERE locus.Gene IN (\"SKOR\", \"MAA3\");\"\"\" #I am creating the joined table using sql syntax\n",
    "        cursor.execute(sql) \n",
    "        results = cursor.fetchall()\n",
    "        report = tsv_append(results)\n",
    "        docc = open(\"JGFReport.txt\", \"a\")            #The opening mode of the document has been changed from write to append in order not to overwrite the file\n",
    "        docc.write(\"\\n \\nHere I have created a joined report that only includes the Genes SKOR and MAA3 and appends the table I have obtained to the text file\" +report)\n",
    "        docc.close()\n",
    "        \n",
    "        connection.commit() \n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the object containing the list of dictionaries is present as results in python I can work with it and use the function I created to transform it in strings that can be written in a text or tsv file. If you wanted to see the table with their columns correctly separated you can open it with libreofficecalc in a simmilar manner to what you'll do to a tsv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a report that counts the number of entries for each Chromosome (AT1Gxxxxxx to AT5Gxxxxxxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM germplasm INNER JOIN locus ON germplasm.Locus = locus.Locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='exam_week_2',\n",
    "                             charset='utf8mb4',  # note utf8... this is important for unusual characters!\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "connection.autocommit = False\n",
    "\n",
    "    \n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        sql = \"\"\"SELECT * FROM germplasm INNER JOIN locus ON germplasm.Locus = locus.Locus;\"\"\" #I am creating the joined table\n",
    "        cursor.execute(sql) \n",
    "        results = cursor.fetchall()\n",
    "        codes = []                  #creating a list called codes\n",
    "        for dicc in results:        #iterating over the dictionaries in the list of dictionaries called resultsresults\n",
    "            codes.append(dicc[\"Locus\"])   #appending the values of the key Locus for all the dicts in the codes list \n",
    "        searchobj = \"\\t\".join(codes)      #joining the values of Locus code AIG with a tab value and saving it into the searchobj object which is a string\n",
    "        mo1 = re.findall( r'AT1G[0-9]+\\t', searchobj)    #doing a regular expresion search for the locus codes from each chromosome and saving it into a mo object. findall returns all the values that match the reg expr.\n",
    "        mo2 = re.findall( r'AT2G[0-9]+\\t', searchobj)\n",
    "        mo3 = re.findall( r'AT3G[0-9]+\\t', searchobj)\n",
    "        mo4 = re.findall( r'AT4G[0-9]+\\t', searchobj)\n",
    "        mo5 = re.findall( r'AT5G[0-9]+\\t?', searchobj)\n",
    "    \n",
    "    lista1 = [{\"Chromosome\" : \"1\", \"Chrom_entries\": len(mo1)}, {\"Chromosome\" : \"2\", \"Chrom_entries\": len(mo2)}, {\"Chromosome\" : \"3\", \"Chrom_entries\": len(mo3)}, {\"Chromosome\" : \"4\", \"Chrom_entries\": len(mo4)}, {\"Chromosome\" : \"5\", \"Chrom_entries\": len(mo5)}] #creating a list of dictionaries with the chromosome number and the number of entries that come from that chromosome.\n",
    "    report = tsv_append(lista1)\n",
    "    docc = open(\"JGFReport.txt\", \"a\")\n",
    "    docc.write(\"\\n\\nI am creating a report that counts the number of entries for each Chromosome (AT1Gxxxxxx to AT5Gxxxxxxx) and outputs it as a table with tab separated values but in a text file\" +report)\n",
    "    docc.close()\n",
    "        \n",
    "    connection.commit()\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I took a different approach, I obtained the results table which is a list of dictionaries, then created a list of codes by iterating over the dictionaries. This list containes the Values for the keys Locus of all the entries.\n",
    "Then using findall over this list I obtained all the results that matched the query for each chromosome and saved them in different objects. After that I created a new list of dictionaries containing the chromosome and the length of the search objects that were lists with all the results for each chromosome. This way I could count the entries for each chromosome and use the previously created function to transform the list in  a string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a report that shows the average protein length for the genes on each Chromosome (AT1Gxxxxxx to AT5Gxxxxxxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                                user='root',\n",
    "                                password='root',\n",
    "                                db='exam_week_2',\n",
    "                                charset='utf8mb4', # note utf8... this is important for unusual characters!\n",
    "                                cursorclass=pymysql.cursors.DictCursor)\n",
    "#onnection.autocommit = False\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        with open('LocusGene.tsv') as csvfile:\n",
    "            loc = open(\"LocusGene.tsv\", \"r\")   #I open the document in read mode and saved it in the loc object\n",
    "            locus = loc.readlines()            #this creates and object that is a list with a line en every index, the values separated by \\t and there is a \\n at the end of each line\n",
    "            import re\n",
    "            mo = re.search( r'([^\\t]+)\\t([^\\t]+)\\t([^\\t]+)[\\n]', locus[0])       #search object to obtain the header values, they are in the index 0 of the list\n",
    "            colnames1 = [mo.group(1), mo.group(2), mo.group(3)]                  #creating a list filled with the header values\n",
    "            sql = \"CREATE TABLE chromosome( \" +colnames1[0] + \" VARCHAR(20) NOT NULL PRIMARY KEY, \" +colnames1[1] + \" VARCHAR(30) NOT NULL, \" + colnames1[2] + \" INTEGER NOT NULL, chromnumber VARCHAR(2) NOT NULL  )\" #using the previous list I write the name for each column\n",
    "            cursor.execute(sql)\n",
    "            connection.commit() \n",
    "\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I have created a new table that will be like the table that came from locusgene but with a new column for the chromosome number of each entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql show databases\n",
    "%sql use exam_week_2\n",
    "%sql show tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql.cursors\n",
    "import csv\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='exam_week_2',\n",
    "                             charset='utf8mb4',  # note utf8... this is important for unusual characters!\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "connection.autocommit = False\n",
    "\n",
    "    \n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        with open('LocusGene.tsv') as csvfile:       #I have filled this new table that contains a new column in a simmilar manner to the described in problem 3\n",
    "            res = csv.DictReader(csvfile, delimiter=\"\\t\", quotechar='\"')   \n",
    "            for row in res:\n",
    "                sql = \"INSERT INTO chromosome (Locus, Gene, ProteinLength, chromnumber ) values   ('{}', '{}',{}, '{}')\".format(row[colnames1[0]], row[colnames1[1]], row[colnames1[2]], row[colnames1[0]][2])\n",
    "                cursor.execute(sql)\n",
    "            connection.commit() \n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from chromosome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in this new table I have the protein length for each entry and the chromosome number to which they belong. This way I can manage to count the average protein length grouping by chromosome number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%sql SELECT chromnumber, AVG(ProteinLength) FROM chromosome GROUP BY chromnumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous box code I was checking if the output of the sql was correct, in this case it is and I can use pymysql to write it into an object and play with it in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql.cursors\n",
    "import csv\n",
    "connection = pymysql.connect(host='localhost',\n",
    "                             user='root',\n",
    "                             password='root',\n",
    "                             db='exam_week_2',\n",
    "                             charset='utf8mb4',  # note utf8... this is important for unusual characters!\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "connection.autocommit = False\n",
    "        \n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        sql = \"\"\"SELECT chromnumber, AVG(ProteinLength) FROM chromosome GROUP BY chromnumber;\"\"\" #thanks to sql syntax I can pair the chromosomes number to the average protein length of the entries for that chromosome\n",
    "        cursor.execute(sql)\n",
    "        results = cursor.fetchall()\n",
    "        report = tsv_append(results)\n",
    "        docc = open(\"JGFReport.txt\", \"a\")\n",
    "        docc.write(\"\\n\\n I am creating a report that shows the average protein length for the genes on each Chromosome (AT1Gxxxxxx to AT5Gxxxxxxx) and is presented as a table with tab separated values\" +report)\n",
    "        docc.close()\n",
    "        connection.commit()\n",
    "finally:\n",
    "    print(\"\")\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the object is present as results in python I can work with it as a list of dictionaries and use the function I created to transform it in strings that can be written in a text or tsvfile. If you wanted to see the table with their columns correctly separated you can open it with libreofficecalc simmilarly to a tsv."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
